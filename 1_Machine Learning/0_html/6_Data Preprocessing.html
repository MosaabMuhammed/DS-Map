<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8" />
    <title>
        ML Data Preprocessing
    </title>
    <link rel="stylesheet" href="../../prism.css">
</head>

<body>
    <h1 id="datapreprocessing">
        Data Preprocessing
    </h1>
    <div style="width:1000px;margin:auto">
        <details>
            <summary>
                <b>
      Train Test Split (Stratified)
     </b> [Categorical]
            </summary>
            <p style="margin: 0">
            </p>
            <p>
                1)
                <a href="file:///media/mosaab/Volume/Personal/Development/Courses%20Docs/Data%20Science/10_%20K-Nearest%20Neighbors/1_step-by-step-diabetes-classification-knn-detailed.html#Test-Train-Split-and-Cross-Validation-methods">
      Explanation for
      <b>
       Train
       <em>
        Test
       </em>
       Split
      </b>
     </a>
                <br/> 2)
                <a href="file:///media/mosaab/Volume/Personal/Development/Courses%20Docs/Data%20Science/10_%20K-Nearest%20Neighbors/2_KNN%20-%20Full%20Pipeline.html#Train-Test-Split">
      Train Test Split notebook
     </a>
            </p>
            <pre class="language-python"><code>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    df_feat, y, test_size=0.4, stratify=y, random_state=42)
</code></pre>
            <p>
                Another way to split, by hashing the unique identifier of each row, to make sure that at the next run, the training and test sets will be the same
            </p>
            <pre class="language-python"><code>from zlib import crc32

def test_set_check(identifier, test_ratio):
    return crc32(np.int64(identifier)) &amp; 0xffffffff &lt; test_ratio * 2**32

def split_train_test_by_id(data, test_ratio, id_column):
    ids         = data[id_column]
    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))
    return data.loc[~in_test_set], data.loc[in_test_set]

housing_with_id = housing.reset_index()    # Since housing doesn't have identifier.
train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, "index")

print(len(train_set)/housing.shape[0], len(test_set)/housing.shape[0])
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Train Test Split (Stratified)
     </b> [Regression]
            </summary>
            <p>
                <details>
                    <summary>
                        <b>
        Manually Chosen bins
       </b>
                    </summary>
                    <p>
                    </p>
                    <h5>
                        Descritize the target column into n bins.
                    </h5>
                    <pre class="language-python"><code>housing['income_cat'] = pd.cut(housing['median_income'],
                               bins=[0., 1.5, 3., 4.5, 6., np.inf],
                               labels=[1, 2, 3, 4, 5])
</code></pre>
                    <h5>
                        Split based on the new categorical binned column
                    </h5>
                    <pre class="language-python"><code>from sklearn.model_selection import StratifiedShuffleSplit

split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(housing, housing['income_cat']):
    strat_train_set = housing.loc[train_index]
    strat_test_set  = housing.loc[test_index]
</code></pre>
                    <h5>
                        Then, remove the binned column.
                    </h5>
                    <pre class="language-python"><code># Remove the "income_cat".
for set_ in (strat_train_set , strat_test_set):
    set_.drop("income_cat", axis=1, inplace=True)
</code></pre>
                </details>
            </p>
        </details>
        <details>
            <summary>
                <b>
      Bins chosen by Sturge's rule
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>from sklearn import model_selection 

def create_folds(data):
    # Create a new column called kfold and fill it with -1.
    data["kfold"] = -1

    # Randomize the rows of the data.
    data = data.sample(frac=1).reset_index(drop=True)

    # Calculate number of bins by Sturge's rule.
    n_bins = np.floor(1 + np.log2(len(data)))

    # Bin targets.
    data.loc[:, "bins"] = pd.cut(data["target"],
                                 bins=n_bins,
                                 labels=False)

    # Initiate the kfold class from model_selection module.
    kf = model_selection.StratifiedKFold(n_splits=5)

    # Fill the new kfold column.
    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):
        data.loc[v_, 'kfold'] = f

    # Drop the bins column.
    data = data.drop("bins", axis=1)

    return data
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Temporal Splitting (Time Based  Splitting)
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>split_train = int(len(data) * .8)
split_test  = int(len(data) * .2)

X_train = data[:split_train]
y_train = data[:split_train]['Target']

X_test = data[-split_test:]
y_test = data[-split_test:]['Target']
</code></pre>
        </details>

        <details>
            <summary>
                <b>
      Time Series Splitting
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>from sklearn.model_selection import TimeSeriesSplit # you have everything done for you
def timeseriesCVscore(params, series, loss_function=mean_squared_error, slen=24):
    """
        Returns error on CV  
        
        params - vector of parameters for optimization
        series - dataset with timeseries
        slen - season length for Holt-Winters model
    """
    # errors array
    errors = []
    
    values = series.values
    alpha, beta, gamma = params
    
    # set the number of folds for cross-validation
    tscv = TimeSeriesSplit(n_splits=3) 
    
    # iterating over folds, train model on each, forecast and calculate error
    for train, test in tscv.split(values):

        model = HoltWinters(series=values[train], slen=slen, 
                            alpha=alpha, beta=beta, gamma=gamma, n_preds=len(test))
        model.triple_exponential_smoothing()
        
        predictions = model.result[-len(test):]
        actual = values[test]
        error = loss_function(predictions, actual)
        errors.append(error)
        
    return np.mean(np.array(errors))
</code></pre>
        </details>

        <details>
            <summary>
                <b>
      Leave-One-Out
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>import numpy as np
from sklearn.model_selection import LeaveOneOut
X = np.array([[1, 2], [3, 4]])
y = np.array([1, 2])
loo = LeaveOneOut()
loo.get_n_splits(X)

print(loo)

for train_index, test_index in loo.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    print(X_train, X_test, y_train, y_test)

# TRAIN: [1] TEST: [0]
# [[3 4]] [[1 2]] [2] [1]
# TRAIN: [0] TEST: [1]
# [[1 2]] [[3 4]] [1] [2]
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Random K-Fold CV
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code># We can use this method with almost all kinds of datasets.
from sklearn import model_selection

# Create a new column called kfold and fill it with -1.
df['kfold'] = -1

# Randomize the rows of the data.
df = df.sample(frac=1).reset_index(drop=True)

# Initiate the kfold class from model_selection module
kf = model_selection.KFold(n_splits=5)

# fill the new kfold column.
for fold, (trn_, val_) in enumerate(kf.split(X=df)):
    df.loc[val_, 'kfold'] = fold

# Save the new csv with kfold column.
df.to_csv("train_folds.csv", index=False)
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Stratified K-Fold CV
     </b>
            </summary>

            <pre class="language-python"><code># Using Custom Stratified K-folds
def Stratified_kfolds(alg, X, y):
    score_valid = 0
    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=33)

    for train_idx, valid_idx in skf.split(X, y):
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

        # One-Hot Encoding
        ohe_enc_keyword  = CountVectorizer()
#         ohe_enc_location = CountVectorizer()
        ohe_enc_text     = CountVectorizer(max_df=.9, min_df=3)

        # Transform Train data
        keyword_train    = ohe_enc_keyword.fit_transform(X_train['keyword'])
#         location_train   = ohe_enc_location.fit_transform(X_train['location'])
        text_train       = ohe_enc_text.fit_transform(X_train['text'])

        # Transform Validation data.
        keyword_valid    = ohe_enc_keyword.transform(X_valid['keyword'])
#         location_valid   = ohe_enc_location.transform(X_valid['location'])
        text_valid       = ohe_enc_text.transform(X_valid['text'])

        ## Merge Training data.
        X_train = hstack((keyword_train, text_train)).tocsr()

        ## Merge Validation data
        X_valid = hstack((keyword_valid, text_valid)).tocsr()

        # ML Models.
        alg.fit(X_train.todense(), y_train)
        y_pred_valid = alg.predict(X_valid.todense())
        score_valid  += f1_score(y_valid, y_pred_valid)

    return score_valid/skf.n_splits
</code></pre>
            <h4>
                Another simple solution
            </h4>
            <pre class="language-python"><code># We can use this method with almost all kinds of datasets.
from sklearn import model_selection

# Create a new column called kfold and fill it with -1.
df['kfold'] = -1

# Randomize the rows of the data.
df = df.sample(frac=1).reset_index(drop=True)
y  = df.target.values

# Initiate the kfold class from model_selection module
kf = model_selection.StratifiedKFold(n_splits=5)

# fill the new kfold column.
for fold, (trn_, val_) in enumerate(kf.split(X=df, y=y)):
    df.loc[val_, 'kfold'] = fold

# Save the new csv with kfold column.
df.to_csv("train_folds.csv", index=False)
</code></pre>
            <h3>Save the prediction of the validation for each fold</h3>
            <pre class="language-python"><code>trainingScores = []
cvScores = []
predictionsBasedOnKFolds = pd.DataFrame(data=[],
                                        index=y_train.index,columns=[0,1])

model = logReg
for train_index, cv_index in k_fold.split(np.zeros(len(X_train))
                                            ,y_train.ravel()):
    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], \
                                X_train.iloc[cv_index,:]
    y_train_fold, y_cv_fold = y_train.iloc[train_index], \
                                y_train.iloc[cv_index]

    model.fit(X_train_fold, y_train_fold)
    loglossTraining = log_loss(y_train_fold,
                                model.predict_proba(X_train_fold)[:,1])
    trainingScores.append(loglossTraining)
    predictionsBasedOnKFolds.loc[X_cv_fold.index,:] = model.predict_proba(X_cv_fold)
                                        
    loglossCV = log_loss(y_cv_fold,
                        predictionsBasedOnKFolds.loc[X_cv_fold.index,1])
    cvScores.append(loglossCV)
    print('Training Log Loss: ', loglossTraining)
    print('CV Log Loss: ', loglossCV)
    
loglossLogisticRegression = log_loss(y_train,
predictionsBasedOnKFolds.loc[:,1])
print('Logistic Regression Log Loss: ', loglossLogisticRegression)
            </code></pre>

        </details>
        <details>
            <summary>
                <b>
      Group K-Fold CV
     </b>
            </summary>
            <p>
            </p>
            <p>
                K-fold iterator variant with non-overlapping groups.
            </p>
            <p>
                The same group will not appear in two different folds (the number of distinct groups has to be at least equal to the number of folds).
            </p>
            <p>
                The folds are approximately balanced in the sense that the number of distinct groups is approximately the same in each fold.
            </p>
            <pre class="language-python"><code>import numpy as np
from sklearn.model_selection import GroupKFold
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])
y = np.array([1, 2, 3, 4])
groups = np.array([0, 0, 2, 2])
group_kfold = GroupKFold(n_splits=2)
group_kfold.get_n_splits(X, y, groups)

print(group_kfold)

for train_index, test_index in group_kfold.split(X, y, groups):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    print(X_train, X_test, y_train, y_test)

### Result ####
TRAIN: [0 1] TEST: [2 3]
[[1 2]
 [3 4]] [[5 6]
 [7 8]] [1 2] [3 4]
TRAIN: [2 3] TEST: [0 1]
[[5 6]
 [7 8]] [[1 2]
 [3 4]] [3 4] [1 2]
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Multi-Label Stratified K-Fold CV
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>from iterstart.ml_startifiers import MultilabelStratifiedKFold

df.loc[:, "kfold"] = -1
df = df.sample(frac=1).reset_index(drop=True)

mskf = MultilabelStratifiedKFold(n_splits=5)
for fold_, (trn_, val_) in enumerate(mskf.split(X=df, y=targets)):
    df.loc[val_, "kfold"] = fold_

df.to_csv("train_folds.csv", index=False)
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Cross_val_score
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>model = RF(n_estimators=100, n_jobs=-1)

# 10 Fold cross validation
cv_results = cross_val_score(model, train_set, train_labels, cv=10, scoring=scorer)

print(f'~&gt; 10 Fold Cross Validation F1 Score = {bg(round(cv_results.mean(), 4), "s")} with std = {bg(round(cv_results.std(), 4), "s")}')
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      cross_val_predict
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code># Returns the predictions 
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, n_jobs=-1, verbose=1, method="predict")

# Predict Proba
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, n_jobs=-1, verbose=1, method="predict_proba")

# Predict decision function
y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, n_jobs=-1, verbose=1, method="decision_function")
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      GridSearchCV
     </b>
            </summary>
            <p style="margin: 0">
            </p>
            <p>
                1)
                <a href="file:///media/mosaab/Volume/Personal/Development/Courses%20Docs/Data%20Science/10_%20K-Nearest%20Neighbors/1_step-by-step-diabetes-classification-knn-detailed.html#Hyper-Parameter-optimization">
      Explanation of
      <b>
       GridSearch
      </b>
      .
     </a>
                <br/> 2)
                <a href="file:///media/mosaab/Volume/Personal/Development/Courses%20Docs/Data%20Science/10_%20K-Nearest%20Neighbors/2_KNN%20-%20Full%20Pipeline.html#Hyperparameter-Tunning-&amp;-Cross-Validation">
      Hyperparameter Tunning &amp; Cross validation
     </a>
            </p>
            <code>
     # Load the model
from sklearn.model_selection import GridSearchCV

# Select the range of parameters
param_grid = {'n_neighbors': np.arange(1, 50)}

# Activate the GridSearchCV
knn = KNeighborsClassifier()
knn_cv = GridSearchCV(knn, param_grid, cv=5)
knn_cv.fit(X, y)

# Calculate the Training score
print('The Best Score for training =', knn_cv.best_score_*100,'%')

# See the Best K value
print('The Best parameters (K) =', knn_cv.best_params_['n_neighbors'])

# Show all resutls.
resutls = pd.DataFrame(knn_cv.cv_results_)[['params', 'mean_test_score', rank_test_score']]

# Sort by test score
results.sort_values('rank_test_score')

# Get the best model.
knn_cv.best_estimator_
    </code>
        </details>
        <details>
            <summary>
                Create a
                <b>
      Pipeline
     </b>
            </summary>
            <p>
            </p>
            <p>
                <a href="file:///media/mosaab/Volume/Personal/Development/Courses%20Docs/Kaggle's%20Notebooks/5_Cargo%20Rican%20HouseHold/1_Costa%20Rican%20Household%20Poverty%20Level%20Prediction.html">
                    <b>
       Notebook
      </b>
                </a>
            </p>
            <pre class="language-python"><code>from sklearn.preprocessing import Imputer, MinMaxScaler
from sklearn.pipeline import Pipeline

pipeline = Pipeline([('imputer', Imputer(strategy='meadian')),
                     ('scaler', MinMaxScaler())])

# Fit and transform the training data
train_set = pipeline.fit_transform(train_set)
test_st   = pipeline.transform(test_set)
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Pipeline on specific columns
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

col_transform = ColumnTransformer(transformers=[['ohe', OneHotEncoder(), ['C', 'D']]], remainder="passthrough")
# The result will be in numpy.
X = col_transform.fit_transform(X)

# TO make again in pandas.
pd.DataFrame(X, columns=col_transform.get_feature_names())
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Custom Transformer
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code>from sklearn.base import BaseEstimator, TransformerMixin

rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin):
    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs
        self.add_bedrooms_per_room = add_bedrooms_per_room
    def fit(self, X, y=None):
        return self # nothing else to do
    def transform(self, X, y=None):
        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]
        population_per_household = X[:, population_ix] / X[:, households_ix]
        if self.add_bedrooms_per_room:
            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
            return np.c_[X, rooms_per_household,
                       population_per_household,
                       bedrooms_per_room]
        else:
            return np.c_[X, rooms_per_household, population_per_household]


attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)
housing_extra_attribs = attr_adder.transform(housing.values)
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Custom Steps
     </b> in Pipeline
            </summary>
            <p>
            </p>
            <p>
                <a href="./6_data_processing/custom_pipelines.html">
                    <b>
       Notebook
      </b>
                </a>
            </p>
            <pre class="language-python"><code>from sklearn.preprocessing import FunctionTransformer
from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
play_data = dataset.drop(['intent', 'family_1', 'family_2', 'family_3'], axis=1).copy()

vectorizer = 'count'

def process_text(df):
    if type(df) == str:
        df = pd.DataFrame([df], columns=['sample'])
    df['sample'] = df['sample'].apply(preprocess)
    return df
def semantic_hashing(df):
    df['sample'] = df['sample'].apply(semhash_corpus)
    return df

def feat_eng(df, apply=True):
    if apply:
        df['n_letters'] = df['sample'].apply(len)
        df['n_words']   = df['sample'].str.count('\S+')
    return df

class Vectorizer(BaseEstimator, TransformerMixin):
    def __init__(self, col, vec_type='count', ngram_range=(1, 1)):
        self.col       = col
        self.vec_type = vec_type
        self._vec      = CountVectorizer(ngram_range=ngram_range, token_pattern=r"[#]*\w+[#]*") \
                         if self.vec_type == 'count' else \
                         TfidfVectorizer(ngram_range=ngram_range, token_pattern=r"[#]*\w+[#]*")

    def fit(self, X, y=None):
        self._vec.fit(X[self.col])
        return self

    def transform(self, X, y=None):
        X_vec = self._vec.transform(X[self.col])
        X = pd.concat([X.reset_index(), pd.DataFrame(X_vec.todense(), columns=self._vec.get_feature_names())], axis=1)
        X = X.drop(['index', self.col], axis=1)
        return X

pipeline = Pipeline([
    ('text_processor', FunctionTransformer(
        func=process_text,
    )),
    ('feat_eng', FunctionTransformer(
        func=feat_eng,
        kw_args={'apply': True}
    )),
    ('sem_hash', FunctionTransformer(
        func=semantic_hashing,
    )),
    ('vectorizer', Vectorizer(col='sample', vec_type='tfidf', ngram_range=(1, 1))),
    ('scaler', StandardScaler())
])

play_data = pipeline.fit_transform(play_data)
dd(play_data)
</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Make Scorer
     </b>
            </summary>
            <p>
            </p>
            <p>
                <a href="file:///media/mosaab/Volume/Personal/Development/Courses%20Docs/Sklearn/sklearn.metrics.make_scorer.html#sklearn-metrics-make-scorer">
                    <b>
       Sklearn Docs
      </b>
                </a>
            </p>
            <pre class="language-python"><code>
from sklearn.metrics import f1_score, make_scorer

scorer = make_scorer(f1_score, greater_is_better=True, average='macro')

</code></pre>
        </details>
        <details>
            <summary>
                <b>
      Paralleism
     </b>
            </summary>
            <p>
            </p>
            <pre class="language-python"><code># Prepare the logging.
import logging

# Logging configuration.
logging.basicConfig(
    level=logging.INFO,
    format="%(processName)-10s %(asctime)s %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
</code></pre>
            <pre class="language-python"><code># Prepare Timing function.
from functools import wraps
import time

def timeit(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        return result, time.time() - start
    return wrapper
</code></pre>
            <pre class="language-python"><code># Prepare validation strategy.
from sklearn.externals import joblib
from sklearn.model_selection import cross_val_score

@timeit
def train_model(path, model, saveto=None, cv=2):
    # Load the corpus data and labels for classification.
    X = df["sample"].values
    y = df['intent'].values

    # Compute cross validation scores.
    scores = cross_val_score(model, X, y, cv=cv)

    # Fit the model on entire dataset.
    model.fit(X, y)

    # Write to disk if specified
    if saveto:
        joblib.dump(model, saveto)

    # Return scores as well as training time via decorator.
    return scores
</code></pre>
            <pre class="language-python"><code># Prepare model.s
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neural_network import MLPClassifier

def fit_naive_bayes(path, saveto=None, cv=2):
    model = Pipeline([
        ("tfidf", TfidfVectorizer()),
        ("clf", MultinomialNB())
    ])

    if saveto is None:
        saveto = f"naive_bayes_{time.time()}.pkl"

    scores, delta = train_model(path, model, saveto, cv)

    logger.info((
        f"\nnaive bayes training took {delta:0.2f} seconds."
        f"with an average score of {scores.mean():0.3f}"
    ))

def fit_logistic_regression(path, saveto=None, cv=2):
    model = Pipeline([
        ("tfidf", TfidfVectorizer()),
        ("clf", LogisticRegression())
    ])

    if saveto is None:
        saveto = f"log_reg_{time.time()}.pkl"

    scores, delta = train_model(path, model, saveto, cv)
    logger.info((
        f"\nlogistic regression training took {delta:0.2f} seconds"
        f"with an average score of {scores.mean():.3f}"
    ))


def fit_multilayer_perceptron(path, saveto=None, cv=2):
    model = Pipeline([
        ("tfidf", TfidfVectorizer()),
        ("clf", MLPClassifier(hidden_layer_sizes=(10, 10), early_stopping=True))
    ])

    if saveto is None:
        saveto = f"multilayer_perceptron_{time.time()}.pkl"

    scores, delta = train_model(path, model, saveto, cv)

    logger.info((
        f"\nmultilayer perceptron training took {delta:.2f} seconds"
        f" with an average score of {scores.mean():.3f}"
    ))
</code></pre>
            <pre class="language-python"><code># Paralleism.
import multiprocessing as mp

def run_parallel(path):
    tasks = [
        fit_naive_bayes, fit_logistic_regression, fit_multilayer_perceptron
    ]
    logger.info("\nbeginning parallel tasks")
    start = time.time()

    procs = []
    for task in tasks:
        proc = mp.Process(name=task.__name__, target=task, args=(path,))
        procs.append(proc)
        proc.start()

    for proc in procs:
        proc.join()

    delta = time.time() - start
    logger.info(f"\ntotal parallel fit time: {delta:.2f} seconds.\n")

run_parallel("./")
</code></pre>
        </details>
    </div>
    <script src="../../prism.js"></script>
</body>

</html>