<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8" />
    <title>
        TS Models
    </title>
    <link rel="stylesheet" href="../../prism.css">
</head>

<body>
    <h1 id="2-forecasting">
        2. Forecasting
    </h1>
    <div style="width:1000px;margin:auto">

        <details>
            <summary><b>Intro to Forecasting</b></summary>
            <a href="./9_models/00-Introduction-to-Forecasting-Revised.html"><strong>Halt-Winter - Evaluation - Stationary</strong></a></p>
        </details>
        <!-- --------------------------- ----------------------------- -->
        <details>
            <summary><b>ARIMA Models</b></summary>
            <ul>
                <details>
                    <summary>AR Model</summary>
                    <p>An autoregressive (AR) model is a representation of a type of random process; as such, it is used to describe certain time-varying processes in nature, economics, etc.<br> The autoregressive model specifies that the output variable
                        depends linearly on its own previous values and on a stochastic term (an imperfectly predictable term); thus the model is in the form of a stochastic difference equation.</p>
                    <pre class="language-python"><code># Create a simulated process.
# AR(1) model
# Rt = μ + ϕRt-1 + εt
# As RHS has only one lagged value(Rt-1)this is called AR model of order 1 where μ is mean and ε is noise at time t
# AR(1) MA(1) model:AR parameter = +0.9
from statsmodels.tsa.arima_model import ARMA
from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.tsa.arima_model import ARIMA
import math
from sklearn.metrics import mean_squared_error

rcParams['figure.figsize'] = 16, 12
plt.subplot(4,1,1)
ar1 = np.array([1, -0.9]) # We choose -0.9 as AR parameter is +0.9
ma1 = np.array([1])
AR1 = ArmaProcess(ar1, ma1)
sim1 = AR1.generate_sample(nsample=1000)
plt.title('AR(1) model: AR parameter = +0.9')
plt.plot(sim1)
</code></pre>
                    <img src="../0_html/imgs/ar.png" alt="">
                    <pre class="language-python"><code># Forecasting.
model = ARMA(sim1, order=(1,0))
result = model.fit()
print(result.summary())
print("μ={} ,ϕ={}".format(result.params[0],result.params[1]))

ARMA Model Results                              
==============================================================================
Dep. Variable:                      y   No. Observations:                 1000
Model:                     ARMA(1, 0)   Log Likelihood               -1415.701
Method:                       css-mle   S.D. of innovations              0.996
Date:                Thu, 02 Aug 2018   AIC                           2837.403
Time:                        14:43:19   BIC                           2852.126
Sample:                             0   HQIC                          2842.998
                                                                              
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.7072      0.288      2.454      0.014       0.142       1.272
ar.L1.y        0.8916      0.014     62.742      0.000       0.864       0.919
                                    Roots                                    
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1            1.1216           +0.0000j            1.1216            0.0000
-----------------------------------------------------------------------------
μ=0.7072025170552714 ,ϕ=0.8915815634822984
</code></pre>
                    <pre class="language-python"><code># Forecasting.
# Predicting simulated AR(1) model 
result.plot_predict(start=900, end=1010)
plt.show()
</code></pre>
                    <img src="../0_html/imgs/ar-forecast.png" alt="" width="600" height="400">
                    <pre class="language-python"><code>rmse = math.sqrt(mean_squared_error(sim1[900:1011], result.predict(start=900,end=999)))
print("The root mean squared error is {}.".format(rmse))
# The root mean squared error is 1.0408054544358292.
# y is predicted plot. Quite neat!
                </code></pre>
                </details>

                <details>
                    <summary>MA Model</summary>
                    <p>The moving-average (MA) model is a common approach for modeling univariate time series. <br>The moving-average model specifies that the output variable depends linearly on the current and various past values of a stochastic (imperfectly
                        predictable) term.<br> MA(1) model <br> Rt = μ + ϵt1 + θϵt-1 <br>It translates to Today's returns = mean + today's noise + yesterday's noise</p>
                    <pre class="language-python"><code># Create a simulated process.
# AR(1) model
# Rt = μ + ϕRt-1 + εt
# As RHS has only one lagged value(Rt-1)this is called AR model of order 1 where μ is mean and ε is noise at time t
# AR(1) MA(1) model:AR parameter = +0.9
from statsmodels.tsa.arima_model import ARMA
from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.tsa.arima_model import ARIMA
import math
from sklearn.metrics import mean_squared_error

rcParams['figure.figsize'] = 16, 6
ar1 = np.array([1])
ma1 = np.array([1, -0.5])
MA1 = ArmaProcess(ar1, ma1)
sim1 = MA1.generate_sample(nsample=1000)
plt.plot(sim1)
</code></pre>
                    <img src="../0_html/imgs/ma.png" alt="">
                    <pre class="language-python"><code># Forecasting and predicting montreal humidity
model = ARMA(humidity["Montreal"].diff().iloc[1:].values, order=(0,3))
result = model.fit()
print(result.summary())
print("μ={} ,θ={}".format(result.params[0],result.params[1]))
result.plot_predict(start=1000, end=1100)
plt.show()
                                ARMA Model Results                              
==============================================================================
Dep. Variable:                      y   No. Observations:                45251
Model:                     ARMA(0, 3)   Log Likelihood             -153516.982
Method:                       css-mle   S.D. of innovations              7.197
Date:                Thu, 02 Aug 2018   AIC                         307043.965
Time:                        14:43:32   BIC                         307087.564
Sample:                             0   HQIC                        307057.686
                                                                                
==============================================================================
                    coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.0008      0.031     -0.025      0.980      -0.061       0.060
ma.L1.y       -0.1621      0.005    -34.507      0.000      -0.171      -0.153
ma.L2.y        0.0386      0.005      8.316      0.000       0.030       0.048
ma.L3.y        0.0357      0.005      7.446      0.000       0.026       0.045
                                    Roots                                    
=============================================================================
                    Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
MA.1            1.4520           -2.2191j            2.6519           -0.1578
MA.2            1.4520           +2.2191j            2.6519            0.1578
MA.3           -3.9867           -0.0000j            3.9867           -0.5000
-----------------------------------------------------------------------------
μ=-0.0007772680242180366 ,θ=-0.16209499431431182
</code></pre>
                    <img src="../0_html/imgs/forcast_ma.png" alt="" width="600" height="400">
                    <pre class="language-python"><code>rmse = math.sqrt(mean_squared_error(humidity["Montreal"].diff().iloc[1000:1101].values, result.predict(start=1000,end=1100)))
print("The root mean squared error is {}.".format(rmse))
# The root mean squared error is 11.345129665763626.
</code></pre>
                </details>

                <details>
                    <summary>ARMA Model</summary>
                    <p>Autoregressive–moving-average (ARMA) models provide a parsimonious description of a (weakly) stationary stochastic process in terms of two polynomials, one for the autoregression and the second for the moving average.<br>It's the fusion
                        of AR and MA models.</p>
                    <p>ARMA(1,1) model <br> Rt = μ + ϕRt-1 + ϵt + θϵt-1 <br>Basically, Today's return = mean + Yesterday's return + noise + yesterday's noise.</p>
                    <pre class="language-python"><code>
from statsmodels.tsa.arima_model import ARMA
from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.tsa.arima_model import ARIMA
import math
from sklearn.metrics import mean_squared_error

# Forecasting and predicting microsoft stocks volume
model = ARMA(microsoft["Volume"].diff().iloc[1:].values, order=(3,3))
result = model.fit()
print(result.summary())
print("μ={}, ϕ={}, θ={}".format(result.params[0],result.params[1],result.params[2]))
result.plot_predict(start=1000, end=1100)
plt.show()

ARMA Model Results                              
==============================================================================
Dep. Variable:                      y   No. Observations:                 3018
Model:                     ARMA(3, 3)   Log Likelihood              -55408.974
Method:                       css-mle   S.D. of innovations       22751607.792
Date:                Thu, 02 Aug 2018   AIC                         110833.948
Time:                        14:43:52   BIC                         110882.047
Sample:                             0   HQIC                        110851.244
                                                                              
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const       -2.03e+04   9914.912     -2.047      0.041   -3.97e+04    -864.350
ar.L1.y        0.2053      0.160      1.287      0.198      -0.107       0.518
ar.L2.y        0.7297      0.179      4.080      0.000       0.379       1.080
ar.L3.y       -0.1413      0.057     -2.467      0.014      -0.254      -0.029
ma.L1.y       -0.8117      0.157     -5.165      0.000      -1.120      -0.504
ma.L2.y       -0.7692      0.258     -2.978      0.003      -1.275      -0.263
ma.L3.y        0.5853      0.130      4.494      0.000       0.330       0.841
                                    Roots                                    
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1           -1.1772           +0.0000j            1.1772            0.5000
AR.2            1.1604           +0.0000j            1.1604            0.0000
AR.3            5.1820           +0.0000j            5.1820            0.0000
MA.1           -1.1579           +0.0000j            1.1579            0.5000
MA.2            1.0075           +0.0000j            1.0075            0.0000
MA.3            1.4647           +0.0000j            1.4647            0.0000
-----------------------------------------------------------------------------
μ=-20297.220687001212, ϕ=0.2053008905725337, θ=0.7296681716172797
</code></pre>
                    <pre class="language-python"><code>rmse = math.sqrt(mean_squared_error(microsoft["Volume"].diff().iloc[1000:1101].values, result.predict(start=1000,end=1100)))
print("The root mean squared error is {}.".format(rmse))
The root mean squared error is 38038241.66905847.
ARMA model shows much better results than AR and MA models.
</code></pre>
                </details>

                <details>
                    <summary>ARIMA Model</summary>
                    <p>Autoregressive–moving-average (ARMA) models provide a parsimonious description of a (weakly) stationary stochastic process in terms of two polynomials, one for the autoregression and the second for the moving average.<br>It's the fusion
                        of AR and MA models.</p>
                    <p>ARMA(1,1) model <br> Rt = μ + ϕRt-1 + ϵt + θϵt-1 <br>Basically, Today's return = mean + Yesterday's return + noise + yesterday's noise.</p>
                    <pre class="language-python"><code>
from statsmodels.tsa.arima_model import ARMA
from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.tsa.arima_model import ARIMA
import math
from sklearn.metrics import mean_squared_error

# Predicting the microsoft stocks volume
rcParams['figure.figsize'] = 16, 6
model = ARIMA(microsoft["Volume"].diff().iloc[1:].values, order=(2,1,0))
result = model.fit()
print(result.summary())
result.plot_predict(start=700, end=1000)
plt.show()

ARIMA Model Results                              
==============================================================================
Dep. Variable:                    D.y   No. Observations:                 3017
Model:                 ARIMA(2, 1, 0)   Log Likelihood              -56385.467
Method:                       css-mle   S.D. of innovations       31647215.014
Date:                Thu, 02 Aug 2018   AIC                         112778.933
Time:                        14:44:02   BIC                         112802.981
Sample:                             1   HQIC                        112787.581
                                                                              
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const       9984.0302   2.48e+05      0.040      0.968   -4.75e+05    4.95e+05
ar.L1.D.y     -0.8716      0.016    -53.758      0.000      -0.903      -0.840
ar.L2.D.y     -0.4551      0.016    -28.071      0.000      -0.487      -0.423
                                    Roots                                    
=============================================================================
                 Real           Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1           -0.9575           -1.1315j            1.4823           -0.3618
AR.2           -0.9575           +1.1315j            1.4823            0.3618
-----------------------------------------------------------------------------

rmse = math.sqrt(mean_squared_error(microsoft["Volume"].diff().iloc[700:1001].values, result.predict(start=700,end=1000)))
print("The root mean squared error is {}.".format(rmse))
# The root mean squared error is 61937593.98493614.
</code></pre>
                    <img src="../0_html/imgs/ARIMA.png" alt="" width="600" height="400">
                </details>

                <details>
                    <summary>SARIMA Model</summary>
                    <p>Adding this letter to the four gives us the ARIMA model which can handle non-stationary data with the help of nonseasonal differences. Great, one more letter to go! <br> S(s) - this is responsible for seasonality and equals the season
                        period length of the series <br> With this, we have three parameters: (P,D,Q) <br> P - order of autoregression for the seasonal component of the model, which can be derived from PACF. But you need to look at the number of significant
                        lags, which are the multiples of the season period length. For example, if the period equals 24 and we see the 24-th and 48-th lags are significant in the PACF, that means the initial P should be 2. <br> Q - similar logic using
                        the ACF plot instead. <br> D - order of seasonal integration. This can be equal to 1 or 0, depending on whether seasonal differeces were applied or not.</p>
                    <pre class="language-python"><code># setting initial values and some bounds for them
ps = range(2, 5)
d=1 
qs = range(2, 5)
Ps = range(0, 2)
D=1 
Qs = range(0, 2)
s = 24 # season length is still 24

# creating list with all the possible combinations of parameters
parameters = product(ps, qs, Ps, Qs)
parameters_list = list(parameters)
len(parameters_list)
</code></pre>
                    <pre class="language-python"><code>def optimizeSARIMA(parameters_list, d, D, s):
    """
        Return dataframe with parameters and corresponding AIC
        
        parameters_list - list with (p, q, P, Q) tuples
        d - integration order in ARIMA model
        D - seasonal integration order 
        s - length of season
    """
    
    results = []
    best_aic = float("inf")

    for param in tqdm_notebook(parameters_list):
        # we need try-except because on some combinations model fails to converge
        try:
            model=sm.tsa.statespace.SARIMAX(ads.Ads, order=(param[0], d, param[1]), 
                                            seasonal_order=(param[2], D, param[3], s)).fit(disp=-1)
        except:
            continue
        aic = model.aic
        # saving best model, AIC and parameters
        if aic < best_aic:
            best_model = model
            best_aic = aic
            best_param = param
        results.append([param, model.aic])

    result_table = pd.DataFrame(results)
    result_table.columns = ['parameters', 'aic']
    # sorting in ascending order, the lower AIC is - the better
    result_table = result_table.sort_values(by='aic', ascending=True).reset_index(drop=True)
    
    return result_table

result_table = optimizeSARIMA(parameters_list, d, D, s)
result_table.head()
# 	parameters	aic
# 0	(2, 3, 1, 1)	3888.642174
# 1	(3, 2, 1, 1)	3888.763568
# 2	(4, 2, 1, 1)	3890.279740
# 3	(3, 3, 1, 1)	3890.513196
# 4	(2, 4, 1, 1)	3892.302849
</code></pre>
                    <pre class="language-python"><code># set the parameters that give the lowest AIC
p, q, P, Q = result_table.parameters[0]

best_model=sm.tsa.statespace.SARIMAX(ads.Ads, order=(p, d, q), 
                                        seasonal_order=(P, D, Q, s)).fit(disp=-1)
print(best_model.summary())
#                                  Statespace Model Results                                 
# ==========================================================================================
# Dep. Variable:                                Ads   No. Observations:                  216
# Model:             SARIMAX(2, 1, 3)x(1, 1, 1, 24)   Log Likelihood               -1936.321
# Date:                            Mon, 04 Jan 2021   AIC                           3888.642
# Time:                                    00:06:39   BIC                           3914.660
# Sample:                                09-13-2017   HQIC                          3899.181
#                                      - 09-21-2017                                         
# Covariance Type:                              opg                                         
# ==============================================================================
#                  coef    std err          z      P>|z|      [0.025      0.975]
# ------------------------------------------------------------------------------
# ar.L1          0.7913      0.270      2.928      0.003       0.262       1.321
# ar.L2         -0.5503      0.306     -1.799      0.072      -1.150       0.049
# ma.L1         -0.7316      0.262     -2.793      0.005      -1.245      -0.218
# ma.L2          0.5651      0.282      2.005      0.045       0.013       1.118
# ma.L3         -0.1811      0.092     -1.964      0.049      -0.362      -0.000
# ar.S.L24       0.3312      0.076      4.351      0.000       0.182       0.480
# ma.S.L24      -0.7635      0.104     -7.361      0.000      -0.967      -0.560
# sigma2      4.574e+07   5.61e-09   8.15e+15      0.000    4.57e+07    4.57e+07
# ===================================================================================
# Ljung-Box (Q):                       43.70   Jarque-Bera (JB):                10.56
# Prob(Q):                              0.32   Prob(JB):                         0.01
# Heteroskedasticity (H):               0.65   Skew:                            -0.28
# Prob(H) (two-sided):                  0.09   Kurtosis:                         4.00
# ===================================================================================
</code></pre>
                    <pre class="language-python"><code>def plotSARIMA(series, model, n_steps):
    """
        Plots model vs predicted values
        
        series - dataset with timeseries
        model - fitted SARIMA model
        n_steps - number of steps to predict in the future
        
    """
    # adding model values
    data = series.copy()
    data.columns = ['actual']
    data['arima_model'] = model.fittedvalues
    # making a shift on s+d steps, because these values were unobserved by the model
    # due to the differentiating
    data['arima_model'][:s+d] = np.NaN
    
    # forecasting on n_steps forward 
    forecast = model.predict(start = data.shape[0], end = data.shape[0]+n_steps)
    forecast = data.arima_model.append(forecast)
    # calculate error, again having shifted on s+d steps from the beginning
    error = mean_absolute_percentage_error(data['actual'][s+d:], data['arima_model'][s+d:])

    plt.figure(figsize=(15, 7))
    plt.title("Mean Absolute Percentage Error: {0:.2f}%".format(error))
    plt.plot(forecast, color='r', label="model")
    plt.axvspan(data.index[-1], forecast.index[-1], alpha=0.5, color='lightgrey')
    plt.plot(data.actual, label="actual")
    plt.legend()
    plt.grid(True);
plotSARIMA(ads, best_model, 50)</code></pre>

                </details>

            </ul>
        </details>

        <!-- --------------------------- ----------------------------- -->
        <details>
            <summary><b>FB Prophet</b></summary>
            <a href="../0_html/9_models/Facebook_Prophet.html">Intro to Prophet</a>
        </details>
    </div>
    <script src="../../prism.js"></script>
</body>

</html>