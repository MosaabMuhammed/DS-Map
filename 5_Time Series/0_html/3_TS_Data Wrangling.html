<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8" />
    <title>
        Time Series - Data Wrangling
    </title>
    <link rel="stylesheet" href="../../prism.css">
</head>

<body>
    <h1 id="3-data-wrangling">
        3. TS - Data Wrangling
    </h1>
    <div style="width:1000px;margin:auto">
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary>Read <b>Date</b> data [pandas]</summary>
            <pre class="language-python"><code>google = pd.read_csv('sample.csv', index_col='Date', parse_dates=['Date'])

# infer datetime if you don't parse the date when reading the csv.
dataset['Month'] = pd.to_datetime(dataset['Month'], infer_datetime_format=True) #convert from string to datetime
</code></pre>
        </details>
        <details>
            <summary>
                Set the
                <b>
      Frequency
     </b> of date
            </summary>
            <pre class="language-python"><code>df_example = df_example.asfreq(freq='1D')</code></pre>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary>Fill <b>Missing</b> Data</summary>
            <pre class="language-python"><code>humidity = humidity.fillna(method="ffill")

# other possible values: ffill - bfill
# ffill: propagate last valid observation forward to next valid
# bfill: use next valid observation to fill gap.</code></pre>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary>From <b>Non-Stationary</b> to <b>Stationary</b></summary>
            <ul>
                <li>
                    <details>
                        <summary><b>differencing</b></summary>
                        <pre class="language-python"><code># First order Differencing - Pandas
decomposed_google_volume.trend.diff()

# First Order Differencing - numpy
ts_diff = np.diff(df['depth_to_groundwater'])
df['depth_to_groundwater_diff_1'] = np.append([0], ts_diff)
                                        </code></pre>
                        <pre class="language-python"><code>from pmdarima.arima.utils import ndiffs
df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/wwwusage.csv', names=['value'], header=0)
y = df.value

## Adf Test
ndiffs(y, test='adf')  # 2

# KPSS test
ndiffs(y, test='kpss')  # 0

# PP test:
ndiffs(y, test='pp')  # 2
                            </code></pre>
                    </details>
                </li>
                <li>
                    <details>
                        <summary>Difference b/w <b>log and moving average</b></summary>
                        <pre class="language-python"><code>indexedDataset_logScale = np.log(indexedDataset)
movingAverage = indexedDataset_logScale.rolling(window=12).mean()
datasetLogScaleMinusMovingAverage = indexedDataset_logScale - movingAverage
datasetLogScaleMinusMovingAverage.dropna(inplace=True)
test_stationarity(datasetLogScaleMinusMovingAverage)</code></pre>
                    </details>
                </li>
                <li>
                    <details>
                        <summary>Difference b/w <b>log and exponential Decay Weight edAverage</b></summary>
                        <pre class="language-python"><code>indexedDataset_logScale = np.log(indexedDataset)
movingAverage = indexedDataset_logScale.rolling(window=12).mean()
exponentialDecayWeightedAverage = indexedDataset_logScale.ewm(halflife=12, min_periods=0, adjust=True).mean()
datasetLogScaleMinusExponentialMovingAverage = indexedDataset_logScale - exponentialDecayWeightedAverage
datasetLogScaleMinusExponentialMovingAverage.dropna(inplace=True)
test_stationarity(datasetLogScaleMinusExponentialMovingAverage)</code></pre>
                    </details>
                </li>
            </ul>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary><b>Timestamp</b> & <b>Period</b> - Conversion</summary>
            <pre class="language-python"><code># Creating a Timestamp
timestamp = pd.Timestamp(2017, 1, 1, 12)
# Timestamp('2017-01-01 12:00:00')

# Creating a period
period = pd.Period('2017-01-01')
# Period('2017-01-01', 'D')

# Checking if the given timestamp exists in the given period
period.start_time < timestamp < period.end_time
# True</code></pre>
            <pre class="language-python"><code># Converting timestamp to period
new_period = timestamp.to_period(freq='H')
# Period('2017-01-01 12:00', 'H')

# Converting period to timestamp
new_timestamp = period.to_timestamp(freq='H', how='start')
# Timestamp('2017-01-01 00:00:00')</code></pre>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary>Find the best order of <b>AR</b> and <b>MA</b></summary>
            <pre class="language-python"><code># pick best order by aic 
# smallest aic value wins
best_aic = np.inf 
best_order = None
best_mdl = None

rng = range(5)
for i in rng:
    for j in rng:
        try:
            tmp_mdl = smt.ARMA(arma22, order=(i, j)).fit(method='mle', trend='nc')
            tmp_aic = tmp_mdl.aic
            if tmp_aic < best_aic:
                best_aic = tmp_aic
                best_order = (i, j)
                best_mdl = tmp_mdl
        except: continue

print('aic: {:6.5f} | order: {}'.format(best_aic, best_order))
# aic: 15326.68109 | order: (2, 2)
# Simply use best_mdl.predict() to predict the next values</code></pre>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary><b>pd.date_range</b></summary>
            <p>date_range is a method that returns a fixed frequency datetimeindex. <br> It is quite useful when creating your own time series attribute for pre-existing data or arranging the whole data around the time series attribute created by you.</p>

            <pre class="language-python"><code># Creating a datetimeindex with daily frequency
dr1 = pd.date_range(start='1/1/18', end='1/9/18')
# DatetimeIndex(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',
#                '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',
#                '2018-01-09'],
#                dtype='datetime64[ns]', freq='D')

# Creating a datetimeindex with monthly frequency
dr2 = pd.date_range(start='1/1/18', end='1/1/19', freq='M')
# DatetimeIndex(['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30',
#                '2018-05-31', '2018-06-30', '2018-07-31', '2018-08-31',
#                '2018-09-30', '2018-10-31', '2018-11-30', '2018-12-31'],
#                dtype='datetime64[ns]', freq='M')

# Creating a datetimeindex without specifying start date and using periods
dr3 = pd.date_range(end='1/4/2014', periods=8)
# DatetimeIndex(['2013-12-28', '2013-12-29', '2013-12-30', '2013-12-31',
#                '2014-01-01', '2014-01-02', '2014-01-03', '2014-01-04'],
#                dtype='datetime64[ns]', freq='D')

# Creating a datetimeindex specifying start date , end date and periods
dr4 = pd.date_range(start='2013-04-24', end='2014-11-27', periods=3)
# DatetimeIndex(['2013-04-24', '2014-02-09', '2014-11-27'], dtype='datetime64[ns]', freq=None)</code></pre>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary>
                Let
                <b>
      Matplotlib
     </b> understand dates
            </summary>
            <pre class="language-python"><code>from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()
</code></pre>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary><b>Tests</b></summary>
            <ul>
                <li>
                    <details>
                        <summary><b>Augmented Dickey-Fuller (ADF) test</b></summary>
                        <p>for detecting stationarity<br>A stationary time series is one where the values are not a function of time.</p>
                        <p>We can convert a non-stationary data to stationary one with taking the first, second, .. difference.</p>
                        <pre class="language-python"><code>def test_stationarity(timeseries):
    #Determine rolling statistics
    movingAverage = timeseries.rolling(window=12).mean()
    movingSTD = timeseries.rolling(window=12).std()

    #Plot rolling statistics
    orig = plt.plot(timeseries, color='blue', label='Original')
    mean = plt.plot(movingAverage, color='red', label='Rolling Mean')
    std = plt.plot(movingSTD, color='black', label='Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)

    #Perform Dickeyâ€“Fuller test:
    print('Results of Dickey Fuller Test:')
    dftest = adfuller(timeseries['#Passengers'], autolag='AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print(dfoutput)
# As microsoft has p-value 0.0003201525 which is less than 0.05, null hypothesis is rejected and this is not a random walk.
# Now google has p-value 0.0000006510 which is more than 0.05, null hypothesis is rejected and this is not a random walk.
                        </code></pre>
                        <img src="../0_html/imgs/dftest.png" alt="">
                    </details>
                </li>
                <!-- ---------------------------------------------------------------------------- -->
                <li>
                    <details>
                        <summary><b>Ljung-Box test</b></summary>
                        A quick way to verify whether the first-order differencing has stationarized a time series is to plot the ACF function and run the Ljung-Box test for the differenced series.
                        <a href="./3_Data_Wragling/Chapter_2_First_Order_Differencing.html">notebook</a>
                    </details>
                </li>
            </ul>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
    </div>
    <script src="../../prism.js"></script>
</body>

</html>