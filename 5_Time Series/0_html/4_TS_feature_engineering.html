<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8" />
    <title>
        [TS]: Feature Engineering
    </title>
    <link rel="stylesheet" href="../../prism.css">
</head>

<body>
    <h1 id="4featureengineeringts">
        4. Feature Engineering (TS)
    </h1>
    <div style="width:1000px;margin:auto">
        <details>
            <summary>
                <b>
                    Lags
                </b> &amp;
                <b>
                    Rolling Window
                </b>
            </summary>
            <details>
                <summary>
                    Tutorials
                </summary>
                <p>
                    First off what each features mathematically does:
                </p>
                <ul>
                    <li>
                        <b>
                            lag_7:
                        </b> sales shifted 7 steps downwards for each group. The example above focuses on one group only as an example. That is why the first value appears on the 7th index.
                    </li>
                    <li>
                        <b>
                            lag_28:
                        </b> sales shifted 28 steps downwads. That is why the first value appears on the 28th index.
                    </li>
                    <li>
                        <b>
                            rmean_7_7:
                        </b> rolling mean sales of a window size of 7 over column lag_7. First value (0.2857) appears on the 13th index because means including nan are nan.
                    </li>
                    <li>
                        <b>
                            rmean_7_28:
                        </b> rolling mean sales of a window size of 7 over column lag_28. First value (0.357) appears on the 34th index because that is the first time the mean formula gets all 7 non-nan values.
                    </li>
                    <li>
                        <b>
                            rmean_28_7:
                        </b> rolling mean sales of a window size of 28 over column lag_7. First value (0.2857) appears on the 3th index because it is the first time the mean formula gets 28 non-nan values.
                    </li>
                    <li>
                        <b>
                            rmean_28_28:
                        </b> rolling mean sales of a window size of 28 over column lag_28. First value appears on 55th index because that is the first time the formula here all non-nan values.
                    </li>
                </ul>
                <br />
                <b>
                    The intuition as far as I can understand is the following:
                </b>
                <br />
                <ul>
                    <li>
                        1. Captures the week-on-week similarity and that too of just the past week. In other words, people are likely to shop this monday similar to the last monday (except it is some special occassion).
                    </li>
                    <li>
                        2. Captures the weekly similarity from a month-to-month perspective. Example: people in the 1st weekend of a month shop more so that weekend looks more similar to first weeks of other months than the previous weekend. (Though 28 is arguable here. A month
                        is generally 30. Interesting would be a variable window depending on when the comparative week starts. Dealing with edge cases like week divided into 2 months will be tricky).
                    </li>
                    <br />
                    <b>
                        Since individual data points are prone to erratic spikes or troughs, mean provides a more
                        "representative" picture.
                    </b>
                    <br />
                    <br />
                    <li>
                        3. Captures the information regarding the sales of the whole previous week ending 7 days in the past i.e. if we are at day 14, then the average is of sales from days 1-7 NOT days 7-14. This provides the information about the whole week and not just a
                        single day sale comparison like lag_7 to bring the lag_7 value into "better weekly context".
                    </li>
                    <li>
                        4. Captures the information regarding the sales of the entire previous 4 weeks ending 7 days in the past i.e. if we are at day 35, then the average is sales from days 1-28.
                    </li>
                    <li>
                        5. Captures the information regarding the sales of the whole week ending 4 weeks ago i.e. if we are on day 35, then the average is of sales from day 1-7. (Assuming for simplicity the month is 28 days), this provides the information of not just a month-to-month
                        comparison of the same day (day 7 of month one vs day 7 of month two), but the entire week leading up to day 7. Again the idea I believe is to capture the whole week and not just a single day sale comparison like lag_28 to bring
                        the lag_28 value into "better weekly context".
                    </li>
                    <li>
                        6. Captures the information regarding the sales of the entire previous 4 weeks ending 4 weeks in the past i.e. if we are at day 56, then the average is of days 1-28. (Assuming for simplicity the month is 28 days), the idea again is to bring the point
                        value of lag_28 into a better context (i.e. of day 28 when being compared to day 56) into a "better monthly context".
                    </li>
                </ul>
                <br />
                <b>
                    How would you "talk" about these features?
                </b>
                <br />
                <ul>
                    <li>
                        Hey let's see how the sales were last friday compared to this friday?
                    </li>
                    <li>
                        Hey let's see how the sales were first weekend of the last month compared to first weekend of this month?
                    </li>
                    <li>
                        May be comparing last saturday to this saturday is too specific. Week-on-week same day trends are more likely to be similar if the prior week went similar too. It would make sense to not just have the last saturday but also the mean of the whole week
                        leading upto that day to give the model the "hint" how normal the whole week was.
                    </li>
                </ul>
            </details>
            <details>
                <summary>
                    Code
                </summary>
                <pre class="language-python"><code>lags = [7, 28]
lag_cols = [f"lag_{lag}" for lag in lags]
for lag, lag_col in zip(lags, lag_cols):
df[lag_col] = dt[['id', 'sales']].groupby("id")['sales'].shift(lag)

wins = [7, 28]
for win in wins:
for lag, lag_col in zip(lags, lag_cols):
    df[f"rmean_{lag}_{win}"] = dt[['id', lag_col]].groupby("id")[lag_col].transform(lambda x: x.rolling(win).mean()
</code></pre>
            </details>
        </details>
        <!-- -------------------------------------------------------- -->
        <details>
            <summary>
                <b>
                    Resampling
                </b>
            </summary>
            <p><b>Upsampling</b> - Time series is resampled from low frequency to high frequency(Monthly to daily frequency). It involves filling or interpolating missing data. </br>
                <b>Downsampling</b> - Time series is resampled from high frequency to low frequency(Weekly to monthly frequency). It involves aggregation of existing data.</p>
            <pre class="language-python"><code>#Resample and compute daily mean
daily = df['Chemical conc.'].resample('D')
daily_mean = daily.mean()
</code></pre>
        </details>
        <!-- -------------------------------------------------------- -->
        <details>
            <summary>
                <b>
                    Aggregation
                </b>
            </summary>
            <pre class="language-python"><code>#Calculate month wise statistics
monthly_stats = df.groupby(by='Month_Year')['Mean temparature'].aggregate([np.mean, np.median, np.std])
monthly_stats.reset_index(inplace=True)
monthly_stats.head(10)
</code></pre>
        </details>
        <!-- -------------------------------------------------------- -->
        <details>
            <summary>
                <b>
                    Rolling
                </b>
            </summary>
            <pre class="language-python"><code>#Now we will calculate weekly moving average on the original time series of mean daily temparature
weekly_moving_average = df['Mean temparature'].rolling(7).mean()

#Now we will calculate monthly moving average on the original time series of mean daily temparature
monthly_moving_average = df['Mean temparature'].rolling(30).mean()

#Let's caluclate the weekly and monthly avergaes with a stride of length 2
weekly_moving_average_2stride = df['Mean temparature'].rolling(7).mean()[::2]
monthly_moving_average_2stride = df['Mean temparature'].rolling(30).mean()[::2]
</code></pre>
        </details>

        <!-- -------------------------------------------------------- -->
        <details>
            <summary>
                <b>Date, Time features</b>
            </summary>
            <pre class="language-python"><code># datetime features
data.index = pd.to_datetime(data.index)
data["hour"] = data.index.hour
data["weekday"] = data.index.weekday
data['is_weekend'] = data.weekday.isin([5,6])*1

df['year'] = pd.DatetimeIndex(df['date']).year
df['month'] = pd.DatetimeIndex(df['date']).month
df['day'] = pd.DatetimeIndex(df['date']).day
df['day_of_year'] = pd.DatetimeIndex(df['date']).dayofyear
df['week_of_year'] = pd.DatetimeIndex(df['date']).weekofyear
df['quarter'] = pd.DatetimeIndex(df['date']).quarter
df['season'] = df['month'] % 12 // 3 + 1

#### NOTE
## The new time features are cyclical. For example,the feature month cycles between 1 and 12 for every year. 
## While the difference between each month increments by 1 during the year, between two years the month feature jumps from 12 (December) to 1 (January). 
## This results in a -11 difference, which can confuse a lot of models.
month_in_year = 12
df['month_sin'] = np.sin(2*np.pi*df['month']/month_in_year)
df['month_cos'] = np.cos(2*np.pi*df['month']/month_in_year)
        </code></pre>
        </details>
        <!-- -------------------------------------------------------- -->
        <details>
            <summary>
                <b>Target encoding for Date, Time features</b>
            </summary>
            <pre class="language-python"><code>def code_mean(data, cat_feature, real_feature):
    """
    Returns a dictionary where keys are unique categories of the cat_feature,
    and values are means over real_feature
    """
    return dict(data.groupby(cat_feature)[real_feature].mean())
</code></pre>
            <pre class="language-python"><code># calculate averages on train set only
test_index = int(len(data.dropna())*(1-test_size))
data['weekday_average'] = list(map(code_mean(data[:test_index], 'weekday', "y").get, data.weekday))
data["hour_average"] = list(map(code_mean(data[:test_index], 'hour', "y").get, data.hour))
</code></pre>
        </details>

        <!-- -------------------------------------------------------- -->
        <details>
            <summary>
                <b>Time-Series to Supervised Learning</b>
            </summary>
            <pre class="language-python"><code>from pandas import DataFrame
from pandas import concat

def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
    """
    Frame a time series as a supervised learning dataset.
    Arguments:
        data: Sequence of observations as a list or NumPy array.
        n_in: Number of lag observations as input (X).
        n_out: Number of observations as output (y).
        dropnan: Boolean whether or not to drop rows with NaN values.
    Returns:
        Pandas DataFrame of series framed for supervised learning.
    """
    n_vars = 1 if type(data) is list else data.shape[1]
    df = DataFrame(data)
    cols, names = list(), list()
    # input sequence (t-n, ... t-1)
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
    # forecast sequence (t, t+1, ... t+n)
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
    # put it all together
    agg = concat(cols, axis=1)
    agg.columns = names
    # drop rows with NaN values
    if dropnan:
        agg.dropna(inplace=True)
    return agg
</code></pre>
        </details>
    </div>
</body>
<script src="../../prism.js"></script>

</html>