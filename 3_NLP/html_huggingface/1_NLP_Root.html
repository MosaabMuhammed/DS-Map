<!DOCTYPE HTML>
<html>
 <head>
  <meta charset="utf-8"/>
  <title>
   Made with Remarkable!
  </title>
  <link href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css" rel="stylesheet"/>
  <style type="text/css">
   body,table tr{background-color:#fff}table tr td,table tr th{border:1px solid #ccc;text-align:left;padding:6px 13px;margin:0}pre code,table,table tr{padding:0}hr,pre code{background:0 0}body{font:16px Helvetica,Arial,sans-serif;line-height:1.4;color:#333;word-wrap:break-word;padding:10px 15px}strong,table tr th{font-weight:700}h1{font-size:2em;margin:.67em 0;text-align:center}h2{font-size:1.75em}h3{font-size:1.5em}h4{font-size:1.25em}h1,h2,h3,h4,h5,h6{font-weight:700;position:relative;margin-top:15px;margin-bottom:15px;line-height:1.1}h1,h2{border-bottom:1px solid #eee}hr{height:0;margin:15px 0;overflow:hidden;border:0;border-bottom:1px solid #ddd}a{color:#4183C4}a.absent{color:#c00}ol,ul{padding-left:15px;margin-left:5px}ol{list-style-type:lower-roman}table tr{border-top:1px solid #ccc;margin:0}table tr:nth-child(2n){background-color:#aaa}table tr td :first-child,table tr th :first-child{margin-top:0}table tr td:last-child,table tr th :last-child{margin-bottom:0}img{max-width:100%}blockquote{padding:0 15px;border-left:4px solid #ccc}code,tt{margin:0 2px;padding:0 5px;white-space:nowrap;border:1px solid #eaeaea;background-color:#f8f8f8;border-radius:3px}pre code{margin:0;white-space:pre;border:none}.highlight pre,pre{background-color:#f8f8f8;border:1px solid #ccc;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}
  </style>
 </head>
 <body>
  <h1 id="huggingface">
   HuggingFace
  </h1>
  <div style="width:1000px;margin:auto">
   <details>
    <summary>
     <b style="font-size:20px">
      Transformers
     </b>
    </summary>
    <ul>
     <details>
      <summary>
       How to use
       <b>
        transformers
       </b>
       library
      </summary>
      <a href="./0_notebooks/02_transformers.html">
       notebook
      </a>
     </details>
     <details>
      <summary>
       Pretraining
       <b>
        RoBERTa
       </b>
       from Scratch
      </summary>
      <a href="./0_notebooks/KantaiBERT.html">
       notebook
      </a>
     </details>
     <details>
      <summary>
       Using
       <b>
        BERT
       </b>
       /
       <b>
        DistilBERT
       </b>
       as Embeddings [Arabic/English]
      </summary>
      Use BERT for embedding and sklearn model after it.
      <a href="./0_notebooks/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.html">
       <b>
        notebook
       </b>
      </a>
      <br/>
      <a href="./0_notebooks/3.03. Generating BERT embedding .html">
       <b>
        Another Detailed Notebook
       </b>
      </a>
      <br/>
      <a href="./0_notebooks/3.04. Extracting embeddings from all encoder layers of BERT.html">
       <b>
        Extract Embedding from any encoder in Bert
       </b>
      </a>
     </details>
     <details>
      <summary>
       Fine-tune BERT for Text Classification
      </summary>
      <a href="./0_notebooks/3.06. Text classification.html">
       <b>
        notebook
       </b>
      </a>
      <br/>
      <a href="./0_notebooks/BERT_Fine_Tuning_Sentence_Classification_DR.html">
       <b>
        notebook
       </b>
      </a>
     </details>
     <details>
      <summary>
       BERT on Question-Answering
      </summary>
      <a href="./0_notebooks/3.09. Q&amp;A with finetuned BERT .html">
       <b>
        notebook
       </b>
      </a>
      <br/>
     </details>
     <details>
      <summary>
       Extract Embeddings from
       <b>
        Albert
       </b>
      </summary>
      <a href="./0_notebooks/4.03. Extracting embeddings with ALBERT.html">
       <b>
        notebook
       </b>
      </a>
      <br/>
     </details>
     <details>
      <summary>
       Extract Embeddings from
       <b>
        RoBERTa
       </b>
      </summary>
      <a href="./0_notebooks/4.05. Exploring the RoBERTa tokenizer .html">
       <b>
        notebook
       </b>
      </a>
      <br/>
     </details>
     <details>
      <summary>
       How to use M-BERT
      </summary>
      <a href="./0_notebooks/7.01. Understanding multilingual BERT .html">
       <b>
        notebook
       </b>
      </a>
      <br/>
      <br/>
     </details>
     <details>
      <summary>
       Get Embedding of Sentence with SentenceBERT
      </summary>
      <a href="./0_notebooks/8.03. Exploring sentence-transformers library .html">
       <b>
        notebook
       </b>
      </a>
      <br/>
      <br/>
     </details>
     <details>
      <summary>
       Cosine Similarity for SentenceBERT
      </summary>
      <a href="./0_notebooks/8.05. Computing sentence similarity .html">
       <b>
        notebook
       </b>
      </a>
      <br/>
      <br/>
     </details>
     <details>
      <summary>
       Text Summarization with BART
      </summary>
      <a href="./0_notebooks/9.05. Performing text summarization with BART .html">
       <b>
        notebook
       </b>
      </a>
      <br/>
      <br/>
     </details>
     <a href="./0_notebooks/transformer_on_text_classification.html">
      <b>
       Different Arch. for text classification problem
      </b>
     </a>
    </ul>
   </details>
   <details>
    <summary>
     <b style="font-size:20px">
      Tokenizers
     </b>
    </summary>
    <ul>
     <b>
      BERT
     </b>
     /
     <b>
      DistilBERT
     </b>
     /
     <b>
      Electra
     </b>
     uses
     <i>
      WordPiece
     </i>
     .
     <br/>
     <b>
      XLNet
     </b>
     uses
     <i>
      SentencePiece
     </i>
     .
     <br/>
     <b>
      GPT-2
     </b>
     /
     <b>
      Roberta
     </b>
     uses
     <i>
      Byte-level BPE
     </i>
     .
     <br/>
     <br/>
     <li>
      <details>
       <summary>
        <b>
         WordPiece
        </b>
       </summary>
       <pre><code>from transformers import BertTokenizer
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
tokenizer.tokenize("I have a new GPU!")
# ['i', 'have', 'a', 'new', 'gp', '##u', '!']
</code></pre>
      </details>
     </li>
     <li>
      <details>
       <summary>
        <b>
         SentencePiece
        </b>
       </summary>
       <pre><code>import transformers as ppb
tokenizer = ppb.XLNetTokenizer.from_pretrained('xlnet-base-cased')
tokenizer.tokenize("Don't you love transformers? We pretty sure you do.")
# ['▁Don',
# "'",
# 't',
# '▁you',
# '▁love',
# '▁transform',
# 'ers',
# '?',
# '▁We',
# '▁pretty',
# '▁sure',
# '▁you',
# '▁do',
# '.']
</code></pre>
      </details>
     </li>
     <li>
      <details>
       <summary>
        <b>
         Byte-level BPE
        </b>
       </summary>
       <pre><code>import transformers as ppb
tokenizer = ppb.GPT2Tokenizer.from_pretrained('gpt2')
tokenizer.tokenize("This is a simple to be tokenized.")
# ['This', 'Ġis', 'Ġa', 'Ġsimple', 'Ġto', 'Ġbe', 'Ġtoken', 'ized', '.']
</code></pre>
      </details>
     </li>
     <li>
      <details>
       <summary>
        Any
        <b>
         other unlist model
        </b>
       </summary>
       <pre><code>import transformers as ppb

tokenizer = ppb.AutoTokenizer.from_pretrained("asafaya/bert-mini-arabic")
tokenizer.tokenize("كيف حالك اليوم؟ و حال أولادك يا عمر")
# ['كيف', 'حال', '##ك', 'اليوم', '؟', 'و', 'حال', 'اولاد', '##ك', 'يا', 'عمر']
</code></pre>
      </details>
     </li>
     <li>
      <details>
       <summary>
        Build
        <b>
         Custom Tokenizer
        </b>
       </summary>
       <a href="https://huggingface.co/docs/tokenizers/python/latest/quicktour.html">
        Quicktour [huggingface's docs]
       </a>
       <br/>
       <a href="https://huggingface.co/docs/tokenizers/python/latest/pipeline.html">
        <b>
         Normalization
        </b>
        ,
        <b>
         Pre-Tokenization
        </b>
        , The
        <b>
         Model
        </b>
        , and
        <b>
         Post-Processing
        </b>
       </a>
       <br/>
       <a href="./0_notebooks/01_training_tokenizers.html">
        Custom Tokenizer
       </a>
      </details>
     </li>
    </ul>
   </details>
   <details>
    <summary>
     <b style="font-size:20px">
      Pipeline
     </b>
    </summary>
    <ul>
     <details>
      <summary>
       How to use
       <b>
        pipelines
       </b>
       [ner, sent_ana, text_extraction, ...]
      </summary>
      <a href="./0_notebooks/03_pipelines.html">
       notebook
      </a>
     </details>
    </ul>
   </details>
  </div>
  <script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js">
  </script>
  <script>
   hljs.initHighlightingOnLoad();
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
  </script>
  <script type="text/javascript">
   MathJax.Hub.Config({"showProcessingMessages" : false,"messageStyle" : "none","tex2jax": { inlineMath: [ [ "$", "$" ] ] }});
  </script>
 </body>
</html>