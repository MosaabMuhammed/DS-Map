<!doctype HTML>
<html>

<head>
    <meta charset="utf-8">
    <title>Made with Remarkable!</title>
    <link rel="stylesheet" href="../../../prism.css">
</head>

<body>
    <h1>Data Cleaning</h1>
    <div style='width:1000px;margin:auto'>

        <details>
            <summary><b style='font-size:20px'>Regex</b></summary>
            <p>
                <ul>
                    <li><a href="./0_notebooks/4-regex.html">FastAI tutorial on Regex</a></li>
                </ul>
            </p>
        </details>
        <hr>

        <details>
            <summary><b style='font-size:20px'>Remove URL</b></summary>
            <h4>Find text contains URL</h4>

            <pre class="language-python"><code>df.loc[df['text'].str.contains('http')]</code></pre>

            <h4>Remove text contains URL</h4>

            <pre class="language-python"><code># First code
import re

def remove_URL(text):
    url = re.compile(r'https?://\S+|www\.\S+')
    return url.sub(r'',text)

# Second Code
pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')

def remove_URL(text):
    no_html= pattern.sub('',text)
    return no_html
</code></pre>

        </details>


        <details>
            <summary><b style='font-size:20px'>Remove Single Character</b></summary>
            <pre class="language-python"><code>#remove all single characters
f_data.text = f_data.text.apply(lambda x:re.sub(r'\s+[a-zA-Z]\s+', '', x))
</code></pre>

        </details>
        <details>
            <summary><b style='font-size:20px'>Remove HTML</b></summary>
            <p>

                <pre class="language-python"><code class="python">def remove_HTML(text):
    html = re.compile(r'&lt;.*?&gt;')
    return html.sub(r'', text)
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Remove emoji</b></summary>
            <p>

                <pre class="language-python"><code class="python"># Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b
def remove_emoji(text):
    emoji_pattern = re.compile(&quot;[&quot;
                           u&quot;\U0001F600-\U0001F64F&quot;  # emoticons
                           u&quot;\U0001F300-\U0001F5FF&quot;  # symbols &amp; pictographs
                           u&quot;\U0001F680-\U0001F6FF&quot;  # transport &amp; map symbols
                           u&quot;\U0001F1E0-\U0001F1FF&quot;  # flags (iOS)
                           u&quot;\U00002702-\U000027B0&quot;
                           u&quot;\U000024C2-\U0001F251&quot;
                           &quot;]+&quot;, flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)
</code></pre>



                <pre class="language-python"><code>def remove_emoji(inputString):
    return inputString.encode('ascii', 'ignore').decode('ascii')
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Remove Punctuations</b></summary>
            <p>

                <pre class="language-python"><code class="python">import string

def remove_punct(text):
    table = str.maketrans('', '', string.punctuation)
    return text.translate(table)
</code></pre>


                <pre class="language-python"><code>general_punctuations = [',', '.', '&quot;', ':', ')', '(', '-', '!', '?', '|', ';', &quot;'&quot;, '$', '&amp;', '/', '[', ']', '&gt;', '%', '=', '#', '*', '+', '\\', '•',  '~', '@', '£', 
 '·', '_', '{', '}', '©', '^', '®', '`',  '&lt;', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', 
 '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', 
 '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', 
 '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']

arabic_punctuations = '''٠١٢٣٤٥٦٧٨٩`÷×؛&lt;&gt;_()*&amp;^%][ـ،/:&quot;؟.,'{}~¦+|!”…“–ـ'''

punctuations_list = arabic_punctuations + ''.join(general_punctuations)


def remove_punctuations(text):
    translator = str.maketrans('', '', punctuations_list)
    return text.translate(translator)
</code></pre>


                <pre class="language-python"><code>def clean_text(x):
    pattern = r'[^a-zA-z0-9\s]'
    text = re.sub(pattern, '', x)
    return x
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Spell Checker</b></summary>
            <p>

                <pre class="language-python"><code class="python">!pip install pyspellchecker

from spellchecker import SpellChecker

spell = SpellChecker()
def correct_spellings(text):
    corrected_text = []
    misspelled_words = spell.unknown(text.split())

    for word in text.split():
        if word in misspelled_words:
            corrected_text.append(spell.correction(word))
        else:
            corrected_text.append(word)
    return &quot; &quot;.join(corrected_text)
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Replace Spaces with 1 space</b></summary>
            <p>

                <pre class="language-python"><code class="python"># Substituting multiple spaces with single space
f_data.text = f_data.text.apply(lambda x:re.sub(r'\s+', ' ', x, flags=re.I))
</code></pre>

            </p>
        </details>
        <details>
            <summary><b style='font-size:20px'>Find Hashtags</b></summary>
            <p>

                <pre class="language-python"><code>import re
from tqdm import tqdm
tqdm.pandas(tqdm())

# Extracting hastags using simple regex
train['hastags'] = train['text'].progress_apply(lambda x: re.findall('#\w*', x))
</code></pre>



                <pre class="language-python"><code>#Finding the hashtags in a tweet
def hashtag(tweet):
    with_hashtag = &quot; &quot;.join([word for word in tweet.split() if word.startswith('#')])
    with_hashtag = with_hashtag.lower().split()
    return with_hashtag
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Clean Numbers</b></summary>
            <p>

                <pre class="language-python"><code>## Why do we want to replace numbers with #s? Because most embeddings have preprocessed their text like this.
def clean_numbers(x):
    if bool(re.search(r'\d', x)):
        x = re.sub('[0-9]{5,}', '#####', x)
        x = re.sub('[0-9]{4}', '####', x)
        x = re.sub('[0-9]{3}', '###', x)
        x = re.sub('[0-9]{2}', '##', x)
    return x
</code></pre>


                <pre class="language-python"><code># Remove the numbers
from string import digits

def remove_numbers(text):
    remove_digits = str.maketrans('', '', digits)
    return text.translate(remove_digits)
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Remove Contractions</b></summary>
            <p>

                <pre class="language-python"><code>contraction_dict = {&quot;ain't&quot;: &quot;is not&quot;, &quot;aren't&quot;: &quot;are not&quot;,&quot;can't&quot;: &quot;cannot&quot;, &quot;'cause&quot;: &quot;because&quot;, &quot;could've&quot;: &quot;could have&quot;, &quot;couldn't&quot;: &quot;could not&quot;, &quot;didn't&quot;: &quot;did not&quot;,  &quot;doesn't&quot;: &quot;does not&quot;, &quot;don't&quot;: &quot;do not&quot;, &quot;hadn't&quot;: &quot;had not&quot;, &quot;hasn't&quot;: &quot;has not&quot;, &quot;haven't&quot;: &quot;have not&quot;, &quot;he'd&quot;: &quot;he would&quot;,&quot;he'll&quot;: &quot;he will&quot;, &quot;he's&quot;: &quot;he is&quot;, &quot;how'd&quot;: &quot;how did&quot;, &quot;how'd'y&quot;: &quot;how do you&quot;, &quot;how'll&quot;: &quot;how will&quot;, &quot;how's&quot;: &quot;how is&quot;,  &quot;I'd&quot;: &quot;I would&quot;, &quot;I'd've&quot;: &quot;I would have&quot;, &quot;I'll&quot;: &quot;I will&quot;, &quot;I'll've&quot;: &quot;I will have&quot;,&quot;I'm&quot;: &quot;I am&quot;, &quot;I've&quot;: &quot;I have&quot;, &quot;i'd&quot;: &quot;i would&quot;, &quot;i'd've&quot;: &quot;i would have&quot;, &quot;i'll&quot;: &quot;i will&quot;,  &quot;i'll've&quot;: &quot;i will have&quot;,&quot;i'm&quot;: &quot;i am&quot;, &quot;i've&quot;: &quot;i have&quot;, &quot;isn't&quot;: &quot;is not&quot;, &quot;it'd&quot;: &quot;it would&quot;, &quot;it'd've&quot;: &quot;it would have&quot;, &quot;it'll&quot;: &quot;it will&quot;, &quot;it'll've&quot;: &quot;it will have&quot;,&quot;it's&quot;: &quot;it is&quot;, &quot;let's&quot;: &quot;let us&quot;, &quot;ma'am&quot;: &quot;madam&quot;, &quot;mayn't&quot;: &quot;may not&quot;, &quot;might've&quot;: &quot;might have&quot;,&quot;mightn't&quot;: &quot;might not&quot;,&quot;mightn't've&quot;: &quot;might not have&quot;, &quot;must've&quot;: &quot;must have&quot;, &quot;mustn't&quot;: &quot;must not&quot;, &quot;mustn't've&quot;: &quot;must not have&quot;, &quot;needn't&quot;: &quot;need not&quot;, &quot;needn't've&quot;: &quot;need not have&quot;,&quot;o'clock&quot;: &quot;of the clock&quot;, &quot;oughtn't&quot;: &quot;ought not&quot;, &quot;oughtn't've&quot;: &quot;ought not have&quot;, &quot;shan't&quot;: &quot;shall not&quot;, &quot;sha'n't&quot;: &quot;shall not&quot;, &quot;shan't've&quot;: &quot;shall not have&quot;, &quot;she'd&quot;: &quot;she would&quot;, &quot;she'd've&quot;: &quot;she would have&quot;, &quot;she'll&quot;: &quot;she will&quot;, &quot;she'll've&quot;: &quot;she will have&quot;, &quot;she's&quot;: &quot;she is&quot;, &quot;should've&quot;: &quot;should have&quot;, &quot;shouldn't&quot;: &quot;should not&quot;, &quot;shouldn't've&quot;: &quot;should not have&quot;, &quot;so've&quot;: &quot;so have&quot;,&quot;so's&quot;: &quot;so as&quot;, &quot;this's&quot;: &quot;this is&quot;,&quot;that'd&quot;: &quot;that would&quot;, &quot;that'd've&quot;: &quot;that would have&quot;, &quot;that's&quot;: &quot;that is&quot;, &quot;there'd&quot;: &quot;there would&quot;, &quot;there'd've&quot;: &quot;there would have&quot;, &quot;there's&quot;: &quot;there is&quot;, &quot;here's&quot;: &quot;here is&quot;,&quot;they'd&quot;: &quot;they would&quot;, &quot;they'd've&quot;: &quot;they would have&quot;, &quot;they'll&quot;: &quot;they will&quot;, &quot;they'll've&quot;: &quot;they will have&quot;, &quot;they're&quot;: &quot;they are&quot;, &quot;they've&quot;: &quot;they have&quot;, &quot;to've&quot;: &quot;to have&quot;, &quot;wasn't&quot;: &quot;was not&quot;, &quot;we'd&quot;: &quot;we would&quot;, &quot;we'd've&quot;: &quot;we would have&quot;, &quot;we'll&quot;: &quot;we will&quot;, &quot;we'll've&quot;: &quot;we will have&quot;, &quot;we're&quot;: &quot;we are&quot;, &quot;we've&quot;: &quot;we have&quot;, &quot;weren't&quot;: &quot;were not&quot;, &quot;what'll&quot;: &quot;what will&quot;, &quot;what'll've&quot;: &quot;what will have&quot;, &quot;what're&quot;: &quot;what are&quot;,  &quot;what's&quot;: &quot;what is&quot;, &quot;what've&quot;: &quot;what have&quot;, &quot;when's&quot;: &quot;when is&quot;, &quot;when've&quot;: &quot;when have&quot;, &quot;where'd&quot;: &quot;where did&quot;, &quot;where's&quot;: &quot;where is&quot;, &quot;where've&quot;: &quot;where have&quot;, &quot;who'll&quot;: &quot;who will&quot;, &quot;who'll've&quot;: &quot;who will have&quot;, &quot;who's&quot;: &quot;who is&quot;, &quot;who've&quot;: &quot;who have&quot;, &quot;why's&quot;: &quot;why is&quot;, &quot;why've&quot;: &quot;why have&quot;, &quot;will've&quot;: &quot;will have&quot;, &quot;won't&quot;: &quot;will not&quot;, &quot;won't've&quot;: &quot;will not have&quot;, &quot;would've&quot;: &quot;would have&quot;, &quot;wouldn't&quot;: &quot;would not&quot;, &quot;wouldn't've&quot;: &quot;would not have&quot;, &quot;y'all&quot;: &quot;you all&quot;, &quot;y'all'd&quot;: &quot;you all would&quot;,&quot;y'all'd've&quot;: &quot;you all would have&quot;,&quot;y'all're&quot;: &quot;you all are&quot;,&quot;y'all've&quot;: &quot;you all have&quot;,&quot;you'd&quot;: &quot;you would&quot;, &quot;you'd've&quot;: &quot;you would have&quot;, &quot;you'll&quot;: &quot;you will&quot;, &quot;you'll've&quot;: &quot;you will have&quot;, &quot;you're&quot;: &quot;you are&quot;, &quot;you've&quot;: &quot;you have&quot;}

def _get_contractions(contraction_dict):
    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))
    return contraction_dict, contraction_re

contractions, contractions_re = _get_contractions(contraction_dict)

def replace_contractions(text):
    def replace(match):
        return contractions[match.group(0)]
    return contractions_re.sub(replace, text)

# Usage
replace_contractions(&quot;this's a text with contraction&quot;)
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Stemming</b></summary>
            <p>
                <h4>1. Snowball Stemmer</h4>

                <pre class="language-python"><code>from nltk.stem import  SnowballStemmer
from nltk.tokenize.toktok import ToktokTokenizer
def stem_text(text):
    tokenizer = ToktokTokenizer()
    stemmer = SnowballStemmer('english')
    tokens = tokenizer.tokenize(text)
    tokens = [token.strip() for token in tokens]
    tokens = [stemmer.stem(token.lower()) for token in tokens]
    return ' '.join(tokens)
</code></pre>


                <h4>2. Porter Stemmer</h4>

                <pre class="language-python"><code>from nltk.stem.porter import PorterStemmer

stemmer = PorterStemmer()
' '.join([stemmer.stem(w).strip(&quot;'&quot;) for w in &quot;dish washer's washed dishes&quot;.split()])

##### Result #######
'dish washer wash dish'
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Lemmatization</b></summary>
            <p>

                <pre class="language-python"><code>import nltk
from nltk.stem import WordNetLemmatizer
from nltk.tokenize.toktok import ToktokTokenizer
nltk.download('wordnet')


def lemma_text(text):
    lemmatizer = WordNetLemmatizer()
    tokenizer  = ToktokTokenizer()
    tokens     = tokenizer.tokenize(text)
    tokens     = [token.strip() for token in tokens]
    tokens     = [lemmatizer.lemmatize(token.lower()) for token in tokens]
    return ' '.join(tokens)
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Remove Stopwords</b></summary>
            <p>
                <p><b>NOTE:</b>Stopwords in NLTK is different than in Sklearn.</p>

                <h4>NLTK</h4>

                <pre class="language-python"><code>import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

stop = stopwords.words('english')

def remove_stopwords(text):
    return ' '.join([word.lower() for word in text.split() if word not in stop])

#### Usage 
tweet['text'] = tweet.text.progress_apply(remove_stopwords)
</code></pre>


                <h4>Sklearn</h4>

                <pre class="language-python"><code>from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words
print(len(sklearn_stop_words))

# You can take the common between NLTK and Sklearn.
print(len(nltk_stop_words.intersection(sklearn_stop_words)))
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Remove Repeating Characters</b></summary>
            <p>

                <pre class="language-python"><code># Credits: https://github.com/motazsaad/process-arabic-text/blob/master/clean_arabic_text.py
def remove_repeating_char(text):
    return re.sub(r'(.)\1+', r'\1', text)
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Remove Diacritics (Arabic)</b></summary>
            <p>

                <pre class="language-python"><code># Credits: https://github.com/motazsaad/process-arabic-text/blob/master/clean_arabic_text.py
arabic_diacritics = re.compile(&quot;&quot;&quot;
                             ّ    | # Tashdid
                             َ    | # Fatha
                             ً    | # Tanwin Fath
                             ُ    | # Damma
                             ٌ    | # Tanwin Damm
                             ِ    | # Kasra
                             ٍ    | # Tanwin Kasr
                             ْ    | # Sukun
                             ـ     # Tatwil/Kashida
                         &quot;&quot;&quot;, re.VERBOSE)

def remove_diacritics(text):
    return re.sub(arabic_diacritics, '', text)
</code></pre>

            </p>
        </details>

        <details>
            <summary><b style='font-size:20px'>Normalize Arabic Characters</b></summary>
            <p>

                <pre class="language-python"><code>def normalize_arabic(text):
    text = re.sub(&quot;[إأآا]&quot;, &quot;ا&quot;, text)
    text = re.sub(&quot;ى&quot;, &quot;ي&quot;, text)
    text = re.sub(&quot;ؤ&quot;, &quot;ء&quot;, text)
    text = re.sub(&quot;ئ&quot;, &quot;ء&quot;, text)
    text = re.sub(&quot;ة&quot;, &quot;ه&quot;, text)
    text = re.sub(&quot;گ&quot;, &quot;ك&quot;, text)
    return text
</code></pre>

            </p>
        </details>

    </div>
    <script src="../../../prism.js"></script>
</body>

</html>