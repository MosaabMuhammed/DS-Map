<!doctype HTML><html><head><meta charset="utf-8"><title>Made with Remarkable!</title><link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css"><style type='text/css'>body,table tr{background-color:#fff}table tr td,table tr th{border:1px solid #ccc;text-align:left;padding:6px 13px;margin:0}pre code,table,table tr{padding:0}hr,pre code{background:0 0}body{font:16px Helvetica,Arial,sans-serif;line-height:1.4;color:#333;word-wrap:break-word;padding:10px 15px}strong,table tr th{font-weight:700}h1{font-size:2em;margin:.67em 0;text-align:center}h2{font-size:1.75em}h3{font-size:1.5em}h4{font-size:1.25em}h1,h2,h3,h4,h5,h6{font-weight:700;position:relative;margin-top:15px;margin-bottom:15px;line-height:1.1}h1,h2{border-bottom:1px solid #eee}hr{height:0;margin:15px 0;overflow:hidden;border:0;border-bottom:1px solid #ddd}a{color:#4183C4}a.absent{color:#c00}ol,ul{padding-left:15px;margin-left:5px}ol{list-style-type:lower-roman}table tr{border-top:1px solid #ccc;margin:0}table tr:nth-child(2n){background-color:#aaa}table tr td :first-child,table tr th :first-child{margin-top:0}table tr td:last-child,table tr th :last-child{margin-bottom:0}img{max-width:100%}blockquote{padding:0 15px;border-left:4px solid #ccc}code,tt{margin:0 2px;padding:0 5px;white-space:nowrap;border:1px solid #eaeaea;background-color:#f8f8f8;border-radius:3px}pre code{margin:0;white-space:pre;border:none}.highlight pre,pre{background-color:#f8f8f8;border:1px solid #ccc;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}</style></head><body><h1>EDA</h1>
<div style='width:1000px;margin:auto'>

<details><summary><b style="font-size:20px">n-gram Viewer with Time</b></summary>


<pre><code>fig, ax = plt.subplots(figsize=(9,6))

for term in terms:
    data[term].plot(ax=ax)

ax.set_title(&quot;Token Frequency over Time&quot;)
ax.set_ylabel(&quot;word count&quot;)
ax.set_xlabel(&quot;publication date&quot;)
ax.set_xlim((&quot;2016-02-29&quot;,&quot;2016-05-25&quot;))
ax.legend()
plt.show()

# NOTE: If you don't have time column, you can display it with index, but convert it to bag-of-words first.
</code></pre>

<p><img src="imgs/20200606-153159.png" alt="" /></p>
</details>

<details><summary><b style="font-size:20px">Network Visualization</b></summary>

Visualize the relationship between each pair of words.
<h4>1. Create the corpus</h4>

<pre><code>import itertools

corpus = []
for sentence in df['sample'].values:
    corpus.extend(sentence.split())

def cooccurrence(corpus):
    possible_pairs = list(itertools.combinations(corpus, 2))
    cooccurring    = dict.fromkeys(possible_pairs, 0)
    for idx, current_token in enumerate(corpus):
        if (idx+1 &lt; len(corpus)) and (tuple((current_token, corpus[idx+1])) in possible_pairs):
            cooccurring[(current_token, corpus[idx+1])] += 1
    return cooccurring

pairs = cooccurrence(corpus)
</code></pre>

<h4>2. Create the network</h4>

<pre><code>import networkx as nx

G = nx.Graph()
G.name = &quot;The Social Network of tokens&quot;

# pairs = cooccurrence(corpus)
for pair, wgt in pairs.items():
    if wgt &gt; 0:
        G.add_edge(pair[0], pair[1], weight=wgt)

# Make some the center!
# TODO: WRITE YOUR WORD OF INTEREST HERE!!
D = nx.ego_graph(G, &quot;corona&quot;)
edges, weights = zip(*nx.get_edge_attributes(D, &quot;weight&quot;).items())

# Push nodes away that are less related to that specific word.
pos = nx.spring_layout(D, k=.5, iterations=40)
nx.draw(D, pos, node_color=&quot;gold&quot;, node_size=50, edgelist=edges,
        width=.5, edge_color=&quot;orange&quot;, with_labels=True, font_size=12)
plt.show()
</code></pre>

</details>

<details><summary><b style="font-size:20px">Heatmap</b> b/w <b style="font-size:20px">Tokens</b></summary>

<h4>1. Create the Matrix</h4>

<pre><code>specific_tokens = ['kill', 'corona', 'viris', 'hi', 'symptoms', 'the', 'treatment']

corpus = []
for sentence in df['sample'].values:
    corpus.append(sentence.split())

def cooccurrence_mtx(corpus, specific_tokens=None, sort_alpha=False):
    if sort_alpha: specific_tokens = sorted(specific_tokens)
    possible_pairs = list(itertools.permutations(specific_tokens, 2))
    cooccurring    = dict.fromkeys(possible_pairs, 0)

    for idx, current_sample in enumerate(corpus):
        for pair in possible_pairs:
            if pair[0] in current_sample and pair[1] in current_sample:
                cooccurring[pair] += 1

    pairs = cooccurring.copy()
    mtx = pd.DataFrame(columns=[&quot;p1&quot;, &quot;p2&quot;, &quot;count&quot;])
    for pair, weight in pairs.items():
        mtx = mtx.append({&quot;p1&quot;:    pair[0],
                        &quot;p2&quot;:    pair[1],
                        &quot;count&quot;: float(weight)}, ignore_index=True)

    mtx = pd.pivot(mtx, index='p1', columns='p2', values='count')
    mtx.fillna(.0, inplace=True)
    return mtx

mtx = cooccurrence_mtx(corpus, specific_tokens, True)


mtx.sample(5)
</code></pre>


<h4>2. Show Heatmap</h4>

<pre><code>
</code></pre>

</details>


</div><script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript">MathJax.Hub.Config({"showProcessingMessages" : false,"messageStyle" : "none","tex2jax": { inlineMath: [ [ "$", "$" ] ] }});</script></body></html>