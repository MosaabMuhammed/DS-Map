<!doctype HTML><html><head><meta charset="utf-8"><title>Made with Remarkable!</title><link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css"><style type='text/css'>body,table tr{background-color:#fff}table tr td,table tr th{border:1px solid #ccc;text-align:left;padding:6px 13px;margin:0}pre code,table,table tr{padding:0}hr,pre code{background:0 0}body{font:16px Helvetica,Arial,sans-serif;line-height:1.4;color:#333;word-wrap:break-word;padding:10px 15px}strong,table tr th{font-weight:700}h1{font-size:2em;margin:.67em 0;text-align:center}h2{font-size:1.75em}h3{font-size:1.5em}h4{font-size:1.25em}h1,h2,h3,h4,h5,h6{font-weight:700;position:relative;margin-top:15px;margin-bottom:15px;line-height:1.1}h1,h2{border-bottom:1px solid #eee}hr{height:0;margin:15px 0;overflow:hidden;border:0;border-bottom:1px solid #ddd}a{color:#4183C4}a.absent{color:#c00}ol,ul{padding-left:15px;margin-left:5px}ol{list-style-type:lower-roman}table tr{border-top:1px solid #ccc;margin:0}table tr:nth-child(2n){background-color:#aaa}table tr td :first-child,table tr th :first-child{margin-top:0}table tr td:last-child,table tr th :last-child{margin-bottom:0}img{max-width:100%}blockquote{padding:0 15px;border-left:4px solid #ccc}code,tt{margin:0 2px;padding:0 5px;white-space:nowrap;border:1px solid #eaeaea;background-color:#f8f8f8;border-radius:3px}pre code{margin:0;white-space:pre;border:none}.highlight pre,pre{background-color:#f8f8f8;border:1px solid #ccc;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}</style></head><body><h1>4. Data Preprocessing</h1>
<div style='width:1000px;margin:auto;'>
<details><summary><b>Read Images</b> with <b>Keras Generator</b></summary><p>

<pre><code>from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen  = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_dir,
                                        target_size=(150, 150), # Resize all images to 150x150
                                        batch_size=20,
                                        class_mode='binary')

valid_generator = test_datagen.flow_from_directory(valid_dir,
                                        target_size=(150, 150), # Resize all images to 150x150
                                        batch_size=20,
                                        class_mode='binary')                
</code></pre>


<h4>When fitting the model with generators</h4>

<pre><code>history = model.fit_generator(train_generator,
                        steps_per_epoch=len(train_df)/batch_size,
                        epochs=30,
                        validation_data=valid_generator,
                        validation_steps=len(valid_df)/batch_size)
</code></pre>

</p></details>
<details><summary>Deal with <b>small images dataset</b> 2,000 images</b></summary>
<p> if you start with a simple convnet architecuture, your model will overfit quickly, here's how you can mitigate that effect:</p>
<ul>
<li>Data Augmentation.</li>
<li>Add Drop-out Layer after Flatten() layer and before Dense layer.</li>
<li>Add Regularization</li>
</ul>

- Use a pretrained Convent.
</details>

<details><summary><b>Data Augmentation</b></summary>

<pre><code># Note: Validation &amp; Test data shouldn't be augmented.
datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=40,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest')

valid_datagen = ImageDataGenerator(rescale=1./255)

# Read the folder of images.
train_generator = datagen.flow_from_directory(
                    train_dir,
                    target_size=(150, 150),
                    batch_size=32,
                    class_mode='binary')

</code></pre>

<h4> Display some images after augmenation</h4>

<pre><code>from tensorflow.keras.preprocessing import image

fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]

# Select one image.
img_path = fnames[3]

# Read the image and resize it.
img = image.load_img(img_path, target_size=(150, 150))

# Convert it to a Numpy array with shape (150, 150, 3)
x = image.img_to_array(img)

x = x.reshape((1,) + x.shape)

i = 0
for batch in datagen.flow(x, batch_size=1):
    plt.figure(i)
    imgplot = plt.imshow(image.array_to_img(batch[0]))
    i += 1
    if i % 4 == 0:
        break

plt.show()
</code></pre>

</details>

</div><script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript">MathJax.Hub.Config({"showProcessingMessages" : false,"messageStyle" : "none","tex2jax": { inlineMath: [ [ "$", "$" ] ] }});</script></body></html>