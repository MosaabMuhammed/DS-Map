<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8" />
    <title>
        PySpark DataFrame
    </title>
    <link rel="stylesheet" href="../prism.css">
</head>

<body>
    <h1 id="3-data-wrangling">
        PySpark DataFrame
    </h1>
    <div style="width:1000px;margin:auto">
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary><b>Load Data into DataFrame</b></summary>
            <ul>

                <li>
                    <details>
                        <summary><b>createDataFrame()</b></summary>
                        <pre class="language-python"><code>import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[1]") \
                    .appName('SparkByExamples.com') \
                    .getOrCreate()
                
data = [('James','','Smith','1991-04-01','M',3000),
('Michael','Rose','','2000-05-19','M',4000),
('Robert','','Williams','1978-09-05','M',4000),
('Maria','Anne','Jones','1967-12-01','F',4000),
('Jen','Mary','Brown','1980-02-17','F',-1)
]

columns = ["firstname","middlename","lastname","dob","gender","salary"]
df = spark.createDataFrame(data=data, schema = columns)
df.show()
+---------+----------+--------+----------+------+------+
# |firstname|middlename|lastname|dob       |gender|salary|
# +---------+----------+--------+----------+------+------+
# |James    |          |Smith   |1991-04-01|M     |3000  |
# |Michael  |Rose      |        |2000-05-19|M     |4000  |
# |Robert   |          |Williams|1978-09-05|M     |4000  |
# |Maria    |Anne      |Jones   |1967-12-01|F     |4000  |
# |Jen      |Mary      |Brown   |1980-02-17|F     |-1    |
# +---------+----------+--------+----------+------+------+
</code></pre>
                    </details>
                </li>

                <li>
                    <details>
                        <summary><b>createDataFrame() with defined schema</b></summary>
                        <pre class="language-python"><code>from pyspark.sql import SparkSession
from pyspark.sql.types import StructType,StructField, StringType, IntegerType

spark = SparkSession.builder.master("local[1]") \
                    .appName('SparkByExamples.com') \
                    .getOrCreate()
                
data2 = [("James","","Smith","36636","M",3000),
    ("Michael","Rose","","40288","M",4000),
    ("Robert","","Williams","42114","M",4000),
    ("Maria","Anne","Jones","39192","F",4000),
    ("Jen","Mary","Brown","","F",-1)
    ]

schema = StructType([ \
    StructField("firstname",StringType(),True), \
    StructField("middlename",StringType(),True), \
    StructField("lastname",StringType(),True), \
    StructField("id", StringType(), True), \
    StructField("gender", StringType(), True), \
    StructField("salary", IntegerType(), True) \
    ])
    
df = spark.createDataFrame(data=data2,schema=schema)
df.printSchema()
df.show(truncate=False)
</code></pre>
                    </details>
                </li>

                <li>
                    <details>
                        <summary><b>From RDD</b></summary>
                        <pre class="language-python"><code>import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()
rdd = spark.sparkContext.parallelize(data)
                
columns = ["language","users_count"]
dfFromRDD1 = rdd.toDF(columns)
dfFromRDD1.printSchema()
</code></pre>
                    </details>
                </li>

                <li>
                    <details>
                        <summary><b>from CSV file</b></summary>
                        <pre class="language-python"><code>import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[1]") \
                    .appName('SparkByExamples.com') \
                    .getOrCreate()
                
df = spark.read.csv("/tmp/resources/zipcodes.csv")
df.printSchema()
</code></pre>
                    </details>
                </li>

                <li>
                    <details>
                        <summary><b>from TXT file</b></summary>
                        <pre class="language-python"><code>import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[1]") \
                    .appName('SparkByExamples.com') \
                    .getOrCreate()

df = spark.read.text("/src/resources/file.txt")
df.printSchema()
</code></pre>
                    </details>
                </li>


                <li>
                    <details>
                        <summary><b>from JSON file</b></summary>
                        <pre class="language-python"><code>import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[1]") \
                    .appName('SparkByExamples.com') \
                    .getOrCreate()

df = spark.read.json("/src/resources/file.json")
df.printSchema()
</code></pre>
                    </details>
                </li>
            </ul>
        </details>
        <!-- ---------------------------------------------------------------------------- -->
        <details>
            <summary><b>DF Operations</b></summary>
            <ul>
                <li>
                    <details>
                        <summary><b>Rename columns</b></summary>
                        <pre class="language-python"><code>import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType,StructField, StringType, IntegerType
from pyspark.sql.functions import *

spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()

dataDF = [(('James','','Smith'),'1991-04-01','M',3000),
    (('Michael','Rose',''),'2000-05-19','M',4000),
    (('Robert','','Williams'),'1978-09-05','M',4000),
    (('Maria','Anne','Jones'),'1967-12-01','F',4000),
    (('Jen','Mary','Brown'),'1980-02-17','F',-1)
]

schema = StructType([
        StructField('name', StructType([
                StructField('firstname', StringType(), True),
                StructField('middlename', StringType(), True),
                StructField('lastname', StringType(), True)
                ])),
            StructField('dob', StringType(), True),
            StructField('gender', StringType(), True),
            StructField('salary', IntegerType(), True)
            ])

df = spark.createDataFrame(data = dataDF, schema = schema)
df.printSchema()

# Example 1
df.withColumnRenamed("dob","DateOfBirth").printSchema()
# Example 2   
df2 = df.withColumnRenamed("dob","DateOfBirth") \
    .withColumnRenamed("salary","salary_amount")
df2.printSchema()

# Example 3 
schema2 = StructType([
    StructField("fname",StringType()),
    StructField("middlename",StringType()),
    StructField("lname",StringType())])
    
df.select(col("name").cast(schema2),
    col("dob"),
    col("gender"),
    col("salary")) \
    .printSchema()    

# Example 4 
df.select(col("name.firstname").alias("fname"),
    col("name.middlename").alias("mname"),
    col("name.lastname").alias("lname"),
    col("dob"),col("gender"),col("salary")) \
    .printSchema()
    
# Example 5
df4 = df.withColumn("fname",col("name.firstname")) \
        .withColumn("mname",col("name.middlename")) \
        .withColumn("lname",col("name.lastname")) \
        .drop("name")
df4.printSchema()

#Example 7
newColumns = ["newCol1","newCol2","newCol3","newCol4"]
df.toDF(*newColumns).printSchema()
                        </code></pre>

                    </details>
                </li>
            </ul>
        </details>
    </div>
    <script src="../prism.js"></script>
</body>

</html>